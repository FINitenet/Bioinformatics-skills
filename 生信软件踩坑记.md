<a name="content">目录</a>

[生信软件踩坑记](#title)
- [Fastq-dump](#fastq-dump)
- [pfastq-dump：多核版fastq-dump](#pfastq-dump)
- [samtools和picard的排序问题](#sort-by-samtools-and-picard)




<h1 name="title">生信软件踩坑记</h1>

<a name="fastq-dump"><h2>Fastq-dump [<sup>目录</sup>](#content)</h2></a>

NCBI的fastq-dump软件一直被大家归为目前网上文档做的最差的软件之一

我们一般使用fastq-dump的方式为:

```
$ fastq-dump /path/to/xxx.sra 
```

但是这个默认使用方法得到结果往往很糟，比如说他默认会把双端测序结果保存到一个文件里，但是如果你加上--split-3之后，他会把原来双端拆分成两个文件，但是原来单端并不会保存成两个文件。 还有你用--gzip就能输出gz格式，能够节省空间的同时也不会给后续比对软件造成压力，比对软件都支持，就是时间要多一点。

这些东西在官方文档并没有特别说明，你只有通过不断的踩坑才能学到这些小知识。

- reads拆分

	默认情况下fastq-dump不对reads进行拆分，对于很早之前的单端测序没有出现问题。但是对于双端测序而言，就会把原本的两条reads合并成一个，后续分析必然会出错。
	
	常见的参数有三类:

	> - --split-spot: 将双端测序分为两份，但是都放在同一个文件中
	> - --split-files: 将双端测序分为两份，放在不同的文件，但是对于一方有而一方没有的reads直接丢弃
	> - --split-3 : 将双端测序分为两份，放在不同的文件，但是对于一方有而一方没有的reads会单独放在一个文件夹里

- read ID

默认双端测序数据拆分后得到两个文件中同一个reads的名字是一样的，但是加上`-I | --readids`之后同一个reads的ID就会加上`.1`和`.2`进行区分。举个例子

| 是否有-I参数 | ID 1 | ID 2 |
|:---:|:---|:---|
| 无 | @SRR5829230.1 1 length=36 | @SRR5829230.1 1 length=36 |
| 有 | @SRR5829230.1.1 1 length=36 | @SRR5829230.1.2 1 length=36 |

问题来了，明明已经可以通过ID后面的"1"和"2"来区分ID，加这个参数干嘛。加完之后还会让后续的BWA报错。所以，没事千万别加

- 原始格式

	默认情况下输出的文件的ID都是SRR开头，但其实原始数据名字不是这样子，比如说`@ST-E00600:143:H3LJWALXX:1:1101:5746:1016 2:N:0:CCTCCTGA,@HWI-ST620:248:HB11HADXX:2:1101:1241:2082#0/1`这种。如果你想看到那种格式，而不是SRR，你需要怎么做呢?

	> - `F|--origfmt`: 仅保留数据名字
	> - `--defline-seq <fmt>`: 定义readsID的显示方式
	> - `--defline-qual <fmt>`: 定义质量的显示方式

	<p align="center"><img src=./picture/Use-Biosoft-Fastq-dump-outfmt.png width=600 /></p>

<a name="pfastq-dump"><h2>pfastq-dump：多核版fastq-dump [<sup>目录</sup>](#content)</h2></a>

平常一个SRA格式的转录组数据往往在3G左右，使用hisat2 mapping甚至不用转换成fastq格式，直接就支持SRA，而如果使用BWA做mapping，则必须转换成fastq格式，一旦SRA文件过大，转换过程也要花费很多时间，一个500G的小麦重测序数据则需要40个小时不止，时间就是金钱，在这浪费时间就是浪费金钱呢！

```
$ git clone https://github.com/inutano/pfastq-dump

$ cd pfastq-dump

$ chmod a+x bin/pfastq-dump
```

当然要想正常使用，前提是要保证NCBI的那个fastq-dump也能正常运行

使用：

```
$ pfastq-dump -t <number of threads> [options] <path to .sra file> [<path> ...]
```

单端

```
$ pfastq-dump--threads 8 --outdir /path/to/outdir /path/to/SRR000001.sra
```

双端

```
$ pfastq-dump--threads 10 --outdir ././SRR5873710.sra --split-3 --gzip
```

<a name="sort-by-samtools-and-picard"><h2>samtools和picard的排序问题 [<sup>目录</sup>](#content)</h2></a>

samtools和picard都有对SAM/BAM文件进行排序的功能，一般都是基于坐标排序，先是对chromosome/contig进行排序，再在chromosome/contig内部基于start site从小到大排序，对start site排序很好理解，可是对chromosome/contig排序的时候是基于什么标准呢？

**基于你提供的`ref.fa`文件中的chromosome/contig的顺序**。当你使用比对工具将fastq文件中的reads比对上参考基因组后会生成SAM文件，SAM文件包含头信息，其中有以`@SQ`开头的头信息记录，reference中有多少条chromosome/contig就会有多少条这样的记录，而且它们的顺序与`ref.fa`是一致的。

当使用samtools或picard对SAM/BAM文件进行排序时，这些工具就会读取头信息，按照头信息指定的顺序来排chromosome/contig。所以进行排序时需要提供保护头信息的SAM/BAM文件。

---

参考资料：

(1) [简书：Fastq-dump: 一个神奇的软件](https://www.jianshu.com/p/a8d70b66794c)

(2) [科学网博客：SRA快速转fastq---即多核版fastq-dump](http://blog.sciencenet.cn/blog-1094241-1086440.html)

(3) [GitHub：pfastq-dump README](https://github.com/inutano/pfastq-dump)
